{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mYSLvRgB3Sel"
   },
   "source": [
    "Importing the Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cbE3ZjDb23el"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from mlxtend.data import iris_data\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.datasets import make_blobs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.datasets import make_circles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fCLGacZR4UZx"
   },
   "source": [
    "Data Collection and Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "7ymxgj2i3RwO",
    "outputId": "e3b996de-fcc8-4dcc-b23d-e53953b13d08"
   },
   "outputs": [],
   "source": [
    "#loading the dataset to a pandas Dataframe\n",
    "sonar_data = pd.read_csv(r'C:\\Users\\mxj210016\\Desktop\\Python_Learning\\Projects\\Project1_SONAR Rock vs Mine Prediction/sonar_data.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "I5iWxSnM42fl",
    "outputId": "1b2221d0-dd71-40b2-c7fc-272017ea53f7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WN_FI_eN48V_",
    "outputId": "5d4d105c-657c-4eec-df90-e2f4a0cbf837"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of rows and columns\n",
    "sonar_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 308
    },
    "id": "q6A1r9J-5aOJ",
    "outputId": "9efbb9de-570b-4d9f-a92a-d6835f3acb2d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n",
       "std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n",
       "50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n",
       "75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "               6           7           8           9   ...          50  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  ...  208.000000   \n",
       "mean     0.121747    0.134799    0.178003    0.208259  ...    0.016069   \n",
       "std      0.061788    0.085152    0.118387    0.134416  ...    0.012008   \n",
       "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
       "25%      0.080900    0.080425    0.097025    0.111275  ...    0.008425   \n",
       "50%      0.106950    0.112100    0.152250    0.182400  ...    0.013900   \n",
       "75%      0.154000    0.169600    0.233425    0.268700  ...    0.020825   \n",
       "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
       "\n",
       "               51          52          53          54          55          56  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \n",
       "std      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n",
       "50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n",
       "75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "               57          58          59  \n",
       "count  208.000000  208.000000  208.000000  \n",
       "mean     0.007949    0.007941    0.006507  \n",
       "std      0.006470    0.006181    0.005031  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003675    0.003100  \n",
       "50%      0.005800    0.006400    0.005300  \n",
       "75%      0.010350    0.010325    0.008525  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_data.describe()  #describe --> statistical measures of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XFlxfDyk5o00",
    "outputId": "4ca928a6-de7b-439e-8a94-bc89a4449189"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    111\n",
       "R     97\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_data.iloc[: ,-1].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6RDFTc26aBI"
   },
   "source": [
    "M --> Mine\n",
    "\n",
    "R --> Rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "id": "Uis1XlFs6M09",
    "outputId": "e7c33de6-9384-44d6-a66d-e60cbf0d8662"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>0.034989</td>\n",
       "      <td>0.045544</td>\n",
       "      <td>0.050720</td>\n",
       "      <td>0.064768</td>\n",
       "      <td>0.086715</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>0.128359</td>\n",
       "      <td>0.149832</td>\n",
       "      <td>0.213492</td>\n",
       "      <td>0.251022</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019352</td>\n",
       "      <td>0.016014</td>\n",
       "      <td>0.011643</td>\n",
       "      <td>0.012185</td>\n",
       "      <td>0.009923</td>\n",
       "      <td>0.008914</td>\n",
       "      <td>0.007825</td>\n",
       "      <td>0.009060</td>\n",
       "      <td>0.008695</td>\n",
       "      <td>0.006930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>0.022498</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.035951</td>\n",
       "      <td>0.041447</td>\n",
       "      <td>0.062028</td>\n",
       "      <td>0.096224</td>\n",
       "      <td>0.114180</td>\n",
       "      <td>0.117596</td>\n",
       "      <td>0.137392</td>\n",
       "      <td>0.159325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012311</td>\n",
       "      <td>0.010453</td>\n",
       "      <td>0.009640</td>\n",
       "      <td>0.009518</td>\n",
       "      <td>0.008567</td>\n",
       "      <td>0.007430</td>\n",
       "      <td>0.007814</td>\n",
       "      <td>0.006677</td>\n",
       "      <td>0.007078</td>\n",
       "      <td>0.006024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "60                                                                         \n",
       "M   0.034989  0.045544  0.050720  0.064768  0.086715  0.111864  0.128359   \n",
       "R   0.022498  0.030303  0.035951  0.041447  0.062028  0.096224  0.114180   \n",
       "\n",
       "          7         8         9   ...        50        51        52        53  \\\n",
       "60                                ...                                           \n",
       "M   0.149832  0.213492  0.251022  ...  0.019352  0.016014  0.011643  0.012185   \n",
       "R   0.117596  0.137392  0.159325  ...  0.012311  0.010453  0.009640  0.009518   \n",
       "\n",
       "          54        55        56        57        58        59  \n",
       "60                                                              \n",
       "M   0.009923  0.008914  0.007825  0.009060  0.008695  0.006930  \n",
       "R   0.008567  0.007430  0.007814  0.006677  0.007078  0.006024  \n",
       "\n",
       "[2 rows x 60 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sonar_data.groupby(60).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 61 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       208 non-null    float64\n",
      " 1   1       208 non-null    float64\n",
      " 2   2       208 non-null    float64\n",
      " 3   3       208 non-null    float64\n",
      " 4   4       208 non-null    float64\n",
      " 5   5       208 non-null    float64\n",
      " 6   6       208 non-null    float64\n",
      " 7   7       208 non-null    float64\n",
      " 8   8       208 non-null    float64\n",
      " 9   9       208 non-null    float64\n",
      " 10  10      208 non-null    float64\n",
      " 11  11      208 non-null    float64\n",
      " 12  12      208 non-null    float64\n",
      " 13  13      208 non-null    float64\n",
      " 14  14      208 non-null    float64\n",
      " 15  15      208 non-null    float64\n",
      " 16  16      208 non-null    float64\n",
      " 17  17      208 non-null    float64\n",
      " 18  18      208 non-null    float64\n",
      " 19  19      208 non-null    float64\n",
      " 20  20      208 non-null    float64\n",
      " 21  21      208 non-null    float64\n",
      " 22  22      208 non-null    float64\n",
      " 23  23      208 non-null    float64\n",
      " 24  24      208 non-null    float64\n",
      " 25  25      208 non-null    float64\n",
      " 26  26      208 non-null    float64\n",
      " 27  27      208 non-null    float64\n",
      " 28  28      208 non-null    float64\n",
      " 29  29      208 non-null    float64\n",
      " 30  30      208 non-null    float64\n",
      " 31  31      208 non-null    float64\n",
      " 32  32      208 non-null    float64\n",
      " 33  33      208 non-null    float64\n",
      " 34  34      208 non-null    float64\n",
      " 35  35      208 non-null    float64\n",
      " 36  36      208 non-null    float64\n",
      " 37  37      208 non-null    float64\n",
      " 38  38      208 non-null    float64\n",
      " 39  39      208 non-null    float64\n",
      " 40  40      208 non-null    float64\n",
      " 41  41      208 non-null    float64\n",
      " 42  42      208 non-null    float64\n",
      " 43  43      208 non-null    float64\n",
      " 44  44      208 non-null    float64\n",
      " 45  45      208 non-null    float64\n",
      " 46  46      208 non-null    float64\n",
      " 47  47      208 non-null    float64\n",
      " 48  48      208 non-null    float64\n",
      " 49  49      208 non-null    float64\n",
      " 50  50      208 non-null    float64\n",
      " 51  51      208 non-null    float64\n",
      " 52  52      208 non-null    float64\n",
      " 53  53      208 non-null    float64\n",
      " 54  54      208 non-null    float64\n",
      " 55  55      208 non-null    float64\n",
      " 56  56      208 non-null    float64\n",
      " 57  57      208 non-null    float64\n",
      " 58  58      208 non-null    float64\n",
      " 59  59      208 non-null    float64\n",
      " 60  60      208 non-null    object \n",
      "dtypes: float64(60), object(1)\n",
      "memory usage: 99.2+ KB\n"
     ]
    }
   ],
   "source": [
    "sonar_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qRShuFc46jLd"
   },
   "outputs": [],
   "source": [
    "# separating data and Labels\n",
    "X = sonar_data.drop(columns=60, axis=1)\n",
    "Y = sonar_data[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mkRRrxIe7D7l",
    "outputId": "4dbba519-c5cf-4721-dafa-3c2c31439206"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "LE = LabelEncoder()\n",
    "y= LE.fit_transform(Y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j912DrKe7L03"
   },
   "source": [
    "Training and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "bTnEFld87GIr"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.1, stratify=Y, random_state=1)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ww4D1Ps379_h",
    "outputId": "5a7bbea6-aafb-4978-c7ef-0e28506f5ee8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 60) (187, 60) (21, 60)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KBvcm4eR8enA",
    "outputId": "4878f4d0-12c2-4d69-8f07-1b23b1b69555"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.60535609  0.20762246  0.05044716 ... -0.07902386  2.67181591\n",
      "   2.65755511]\n",
      " [-0.74123519 -1.18573012 -0.6803672  ... -0.36465131 -0.51829817\n",
      "   0.12457456]\n",
      " [-0.6070388  -0.91648324 -0.92203092 ... -1.07120341 -0.72669758\n",
      "  -0.63332513]\n",
      " ...\n",
      " [-0.76899995 -1.02754758 -0.43870349 ... -0.30451921 -0.85494337\n",
      "  -0.25437528]\n",
      " [ 4.0111677   2.65440342  1.27041218 ...  0.88308964 -0.18165296\n",
      "   0.42374549]\n",
      " [-0.44507765 -0.09528028 -0.76189231 ...  0.49223103  1.82218754\n",
      "   1.83982123]]\n",
      "[0 1 1 0 1 1 1 0 1 1 0 0 1 1 0 1 1 0 1 1 0 1 1 1 0 0 1 1 0 0 0 0 1 1 0 0 1\n",
      " 0 0 0 1 0 0 1 0 0 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0\n",
      " 0 1 1 1 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 0 0 1 1 1 0 0 0\n",
      " 0 1 0 0 0 1 0 1 1 0 0 1 1 1 0 1 0 1 0 0 0 1 1 0 0 1 1 1 0 1 0 1 0 1 0 1 1\n",
      " 0 0 0 1 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 0 1 0 1 0 1 0 1 1 0 0 0 1 0 1 0 1 0\n",
      " 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rKLgrLOx8LQx"
   },
   "source": [
    "Model Training --> Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "UoM3FhQS8FAw"
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GGomegF-8TPv",
    "outputId": "688846eb-1b29-4e7f-9905-7956d013dc72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training the Logistic Regression model with training data\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "585vgP7b8vBn"
   },
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "kCBykEtO8pLi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy on training data\n",
    "Y_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(Y_train_prediction, Y_train) \n",
    "Y_train_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "50Wqy2Rc9nL1",
    "outputId": "cc9d8c2e-92ee-4047-e6c6-3bee7fbb359c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data :  0.9197860962566845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7619047619047619"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy on training data : ', training_data_accuracy)\n",
    "model.score(X_train, Y_train)\n",
    "model.score(X_test, Y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "RCUZ6MuR9tOV"
   },
   "outputs": [],
   "source": [
    "#accuracy on test data\n",
    "X_test_prediction = model.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(X_test_prediction, Y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04AsqCrz99vU",
    "outputId": "41e1fed1-ef90-4937-9d9a-a7d23a16504e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data :  0.7619047619047619\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy on test data : ', test_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKrIzmr8-K9s"
   },
   "source": [
    "Making a Predictive System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NMp-UfOd-B7B",
    "outputId": "a7aaeda1-f37b-4719-ab0a-01571db68419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "The object is a mine\n"
     ]
    }
   ],
   "source": [
    "input_data = (0.0307,0.0523,0.0653,0.0521,0.0611,0.0577,0.0665,0.0664,0.1460,0.2792,0.3877,0.4992,0.4981,0.4972,0.5607,0.7339,0.8230,0.9173,0.9975,0.9911,0.8240,0.6498,0.5980,0.4862,0.3150,0.1543,0.0989,0.0284,0.1008,0.2636,0.2694,0.2930,0.2925,0.3998,0.3660,0.3172,0.4609,0.4374,0.1820,0.3376,0.6202,0.4448,0.1863,0.1420,0.0589,0.0576,0.0672,0.0269,0.0245,0.0190,0.0063,0.0321,0.0189,0.0137,0.0277,0.0152,0.0052,0.0121,0.0124,0.0055)\n",
    "\n",
    "# changing the input_data to a numpy array\n",
    "input_data_as_numpy_array = np.asarray(input_data)\n",
    "\n",
    "# reshape the np array as we are predicting for one instance\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
    "\n",
    "prediction = model.predict(input_data_reshaped)\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0]=='R'):\n",
    "  print('The object is a Rock')\n",
    "else:\n",
    "  print('The object is a mine')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "tcg9Er11_TSv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: M\n",
      "True: M\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "row=100\n",
    "x1=X.iloc[row,:]\n",
    "x=scaler.transform(np.asarray(x1).reshape(1,-1))\n",
    "y_pred=model.predict(np.array(x))\n",
    "y_true=Y[row]\n",
    "if y_pred==1:\n",
    "    y_pred='R'\n",
    "else:\n",
    "    y_pred='M'\n",
    "        \n",
    "print('Predicted:', y_pred)\n",
    "print('True:', y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.87837631,  0.45331023,  1.13356647,  1.85811622,  2.02036804,\n",
       "         3.34682196,  2.90002801,  1.17559934,  1.73211881,  1.2437268 ,\n",
       "         0.4914018 ,  0.28460846, -0.30959421, -0.95082263, -0.80583525,\n",
       "        -0.58967183,  0.11438927,  0.55420622,  0.67676163,  0.91049483,\n",
       "         0.85869032,  0.59035877,  0.83297545,  0.24325102, -1.09714727,\n",
       "        -1.88969297, -1.48883072, -1.31945753, -0.805397  ,  0.22514063,\n",
       "         1.13907427,  1.41349545,  1.77736694,  1.67818972,  0.84694787,\n",
       "         0.78813997,  1.17155453,  1.83558978,  1.51651393,  1.24393038,\n",
       "         0.66419801, -0.59049781, -0.59940709,  0.31450019, -0.03616106,\n",
       "         0.02819364, -0.71333611, -1.14237747, -0.24299552, -0.21748808,\n",
       "        -0.4684912 ,  0.59968232,  0.16536093, -0.5948343 , -0.71394584,\n",
       "        -0.48944799, -0.51091797, -0.00385874, -0.82288192, -0.7529935 ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=Y_train\n",
    "y_test=Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.930 CV: 0.764 Test: 0.652 [Logistic Regression]\n",
      "Train: 1.000 CV: 0.826 Test: 0.783 [Random Forest]\n",
      "Train: 0.973 CV: 0.829 Test: 0.783 [SVM]\n",
      "Train: 0.930 CV: 0.731 Test: 0.783 [SGD]\n",
      "Train: 0.757 CV: 0.717 Test: 0.652 [Naive Bayes]\n",
      "Train: 0.892 CV: 0.808 Test: 0.913 [KNN]\n",
      "Train: 0.989 CV: 0.818 Test: 0.913 [NN]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Classifiers--------------------------------------------------\n",
    "clf_LR = LogisticRegression(max_iter=10000).fit(X_train, y_train)\n",
    "clf_RF = RandomForestClassifier().fit(X_train, y_train)\n",
    "clf_SVM = SVC().fit(X_train, y_train)\n",
    "clf_SGD = SGDClassifier().fit(X_train, y_train)\n",
    "clf_NB = GaussianNB().fit(X_train, y_train)\n",
    "clf_KNN = KNeighborsClassifier().fit(X_train, y_train)\n",
    "clf_NN=MLPClassifier(solver='adam', alpha=1e-2,hidden_layer_sizes=(4, 2), max_iter=5000, random_state=0).fit(X_train, y_train)\n",
    "clf_Ens= EnsembleVoteClassifier(clfs=[clf_LR, clf_RF, clf_SVM, clf_SGD], weights=[1, 1, 1], voting='soft')\n",
    "\n",
    "class_model={\n",
    "            'Logistic Regression':clf_LR,\n",
    "            'Random Forest':clf_RF,\n",
    "            'SVM':clf_SVM,\n",
    "            \"SGD\":clf_SGD,\n",
    "            'Naive Bayes':clf_NB,\n",
    "            'KNN':clf_KNN,\n",
    "            'NN':clf_NN\n",
    "#             'Ens':clf_Ens\n",
    "            }\n",
    "\n",
    "class_score={}\n",
    "\n",
    "#Model selection comparision--------------------------------------------\n",
    "for name,model in class_model.items():\n",
    "\n",
    "    score_test=model.score(X_test, y_test)\n",
    "    score_train=model.score(X_train, y_train)\n",
    "    score_cv= cross_val_score(model, X_train, y_train, cv=10, scoring='f1_macro').mean()\n",
    "    class_score[name]=[score_train, score_cv, score_test]\n",
    "    \n",
    "    print(\"Train: %0.3f\" % (float(score_train.round(3))), \"CV: %0.3f\" % (float(score_cv.round(3))), \n",
    "          'Test: %0.3f [%s]' % (float(score_test.round(3)), name))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/80 [00:02<03:55,  2.98s/trial, best loss: -0.7552631578947369]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-199-bbfe5debccc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mtrials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m best = fmin(fn= objective,\n\u001b[0m\u001b[0;32m     30\u001b[0m             \u001b[0mspace\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mallow_trials_fmin\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fmin\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m         return trials.fmin(\n\u001b[0m\u001b[0;32m    508\u001b[0m             \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m             \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    680\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m         return fmin(\n\u001b[0m\u001b[0;32m    683\u001b[0m             \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;31m# next line is where the fmin is actually executed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    290\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m                     \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    168\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"job exception: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    905\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m             )\n\u001b[1;32m--> 907\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-199-bbfe5debccc3>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(space)\u001b[0m\n\u001b[0;32m     20\u001b[0m                                  )\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# We aim to maximize accuracy, therefore we return it as a negative value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,\n\u001b[0m\u001b[0;32m    402\u001b[0m                                 \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'score'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    240\u001b[0m     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n\u001b[0;32m    241\u001b[0m                         pre_dispatch=pre_dispatch)\n\u001b[1;32m--> 242\u001b[1;33m     scores = parallel(\n\u001b[0m\u001b[0;32m    243\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    244\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    374\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMAX_INT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m             trees = [self._make_estimator(append=False,\n\u001b[0m\u001b[0;32m    377\u001b[0m                                           random_state=random_state)\n\u001b[0;32m    378\u001b[0m                      for i in range(n_more_estimators)]\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    374\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMAX_INT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m             trees = [self._make_estimator(append=False,\n\u001b[0m\u001b[0;32m    377\u001b[0m                                           random_state=random_state)\n\u001b[0;32m    378\u001b[0m                      for i in range(n_more_estimators)]\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py\u001b[0m in \u001b[0;36m_make_estimator\u001b[1;34m(self, append, random_state)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[0msub\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \"\"\"\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m         estimator.set_params(**{p: getattr(self, p)\n\u001b[0;32m    153\u001b[0m                                 for p in self.estimator_params})\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mnew_object_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[0mparams_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;31m# quick sanity check of the parameters of the clone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mget_params\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \"\"\"\n\u001b[0;32m    204\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_get_param_names\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[0minit_signature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[1;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m         parameters = [p for p in init_signature.parameters.values()\n\u001b[0m\u001b[0;32m    177\u001b[0m                       if p.name != 'self' and p.kind != p.VAR_KEYWORD]\n\u001b[0;32m    178\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[1;31m# Consider the constructor parameters excluding 'self'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m         parameters = [p for p in init_signature.parameters.values()\n\u001b[1;32m--> 177\u001b[1;33m                       if p.name != 'self' and p.kind != p.VAR_KEYWORD]\n\u001b[0m\u001b[0;32m    178\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVAR_POSITIONAL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\inspect.py\u001b[0m in \u001b[0;36mname\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2527\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2528\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2529\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2531\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "\n",
    "space = {\n",
    "        #'criterion': hp.choice('criterion', ['entropy', 'gini']),\n",
    "        'max_depth': hp.quniform('max_depth', 10, 1200, 10),\n",
    "        'max_features': hp.choice('max_features', ['auto', 'sqrt','log2', None]),\n",
    "       # 'min_samples_leaf': hp.uniform ('min_samples_leaf', 0, 1),\n",
    "        #'min_samples_split' : hp.uniform ('min_samples_split', 1, 3),\n",
    "        'n_estimators' : hp.choice('n_estimators', [10, 50, 100, 300, 750, 1200])\n",
    "        }\n",
    "\n",
    "def objective(space):\n",
    "    model = RandomForestClassifier(\n",
    "                            #    criterion = space['criterion'], \n",
    "                                max_depth = space['max_depth'],\n",
    "                                max_features = space['max_features'],\n",
    "                               # min_samples_leaf = space['min_samples_leaf'],\n",
    "                                #min_samples_split = space['min_samples_split'],\n",
    "                                n_estimators = space['n_estimators'], \n",
    "                                 )\n",
    "    \n",
    "    accuracy = cross_val_score(model, X_train, y_train, cv = 10).mean()\n",
    "\n",
    "    # We aim to maximize accuracy, therefore we return it as a negative value\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }\n",
    " \n",
    "    \n",
    "trials = Trials()\n",
    "best = fmin(fn= objective,\n",
    "            space= space,\n",
    "            algo= tpe.suggest,\n",
    "            max_evals = 80,\n",
    "            trials= trials)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.7142857142857143\n"
     ]
    }
   ],
   "source": [
    "crit = {0: 'entropy', 1: 'gini'}\n",
    "feat = {0: 'auto', 1: 'sqrt', 2: 'log2', 3: None}\n",
    "est = {0: 10, 1: 50, 2: 300, 3: 750, 4: 1200}\n",
    "\n",
    "trainedforest = RandomForestClassifier(\n",
    "                                       #criterion = crit[best['criterion']], \n",
    "                                       max_depth = best['max_depth'], \n",
    "                                       max_features = feat[best['max_features']], \n",
    "#                                        min_samples_leaf = best['min_samples_leaf'], \n",
    "#                                        min_samples_split = best['min_samples_split'], \n",
    "                                       n_estimators = est[best['n_estimators']]\n",
    "                                      ).fit(X_train,y_train)\n",
    "\n",
    "print(trainedforest.score(X_train,y_train))\n",
    "print(trainedforest.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 48 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_train = 1.000\n",
      "score_CV= 0.859\n",
      "score_test = 0.870\n",
      "{'SVM__C': 10000, 'SVM__degree': 1, 'SVM__gamma': 0.01, 'SVM__kernel': 'rbf'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 480 out of 480 | elapsed:    2.8s finished\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "steps = [('scaler', StandardScaler()), ('SVM', SVC())]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Method1 - defining parameters\n",
    "SVM__C=[0.001,0.1,10,100,1000, 10000 , 20000]\n",
    "SVM__C=[10000 , 20000]\n",
    "\n",
    "SVM__kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "SVM__gamma=[0.1,0.01]\n",
    "SVM__degree=[1, 2 ,3]\n",
    "\n",
    "param_svm = dict(SVM__C=SVM__C, SVM__kernel=SVM__kernel, SVM__gamma=SVM__gamma, SVM__degree=SVM__degree)\n",
    "\n",
    "# Method2 - All parameters\n",
    "parameteres = {'SVM__kernel':['linear', 'poly', 'rbf', 'sigmoid'], 'SVM__C':[0.001,0.1,10,100,1000, 10000 , 20000], \n",
    "               'SVM__gamma':['auto', 'scale'], 'SVM__degree':[1, 2 ,3]}\n",
    "\n",
    "grid_pipe = GridSearchCV(pipeline, param_grid=param_svm, cv=10,n_jobs=1, verbose=1, scoring='f1_macro')\n",
    "\n",
    "grid_pipe.fit(X_train, y_train)\n",
    "\n",
    "print (\"score_train = %3.3f\" % (grid_pipe.score(X_train,y_train)))\n",
    "\n",
    "print (\"score_CV= %3.3f\" % grid_pipe.best_score_)\n",
    "\n",
    "print (\"score_test = %3.3f\" % (grid_pipe.score(X_test,y_test)))\n",
    "\n",
    "#pparam=pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "print (grid_pipe.best_params_)\n",
    "\n",
    "#print (\"total time elapsed = %3.3f\"%(endT-startT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score_train = 1.000\n",
      "score_CV= 0.865\n",
      "score_test = 0.870\n"
     ]
    }
   ],
   "source": [
    "clf_SVM = SVC(C=10000, degree=1, gamma=0.01, kernel= 'rbf').fit(X_train, y_train)\n",
    "score_test=clf_SVM.score(X_test, y_test)\n",
    "score_train=clf_SVM.score(X_train, y_train)\n",
    "score_cv= cross_val_score(clf_SVM, X_train, y_train, cv=10, scoring='f1_macro').mean()\n",
    "print (\"score_train = %3.3f\" % score_train)\n",
    "\n",
    "print (\"score_CV= %3.3f\" % score_cv)\n",
    "\n",
    "print (\"score_test = %3.3f\" % score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: M\n",
      "True: R\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "row=20\n",
    "x=X.iloc[row,:]\n",
    "y_pred=clf_SVM.predict(np.array(x).reshape(1,-1))\n",
    "y_true=Y[row]\n",
    "if y_pred==1:\n",
    "    y_pred='R'\n",
    "else:\n",
    "    y_pred='M'\n",
    "        \n",
    "print('Predicted:', y_pred)\n",
    "print('True:', y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.05\n",
      "1 0.05862068965517242\n",
      "2 0.06724137931034482\n",
      "3 0.07586206896551724\n",
      "4 0.08448275862068966\n",
      "5 0.09310344827586207\n",
      "6 0.10172413793103449\n",
      "7 0.1103448275862069\n",
      "8 0.11896551724137931\n",
      "9 0.12758620689655173\n",
      "10 0.13620689655172413\n",
      "11 0.14482758620689656\n",
      "12 0.15344827586206897\n",
      "13 0.16206896551724137\n",
      "14 0.1706896551724138\n",
      "15 0.17931034482758623\n",
      "16 0.1879310344827586\n",
      "17 0.19655172413793104\n",
      "18 0.20517241379310347\n",
      "19 0.21379310344827585\n",
      "20 0.22241379310344828\n",
      "21 0.2310344827586207\n",
      "22 0.23965517241379308\n",
      "23 0.2482758620689655\n",
      "24 0.25689655172413794\n",
      "25 0.2655172413793103\n",
      "26 0.27413793103448275\n",
      "27 0.2827586206896552\n",
      "28 0.29137931034482756\n",
      "29 0.3\n"
     ]
    }
   ],
   "source": [
    "s=np.linspace(0.05, 0.3, 30)\n",
    "scoretest=[]\n",
    "scoretrain=[]\n",
    "scorecv=[]\n",
    "for i, j in enumerate(s):\n",
    "    print(i,j)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = j, stratify=Y, random_state=1)\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    clf_SVM = SVC(C=10000, degree=1, gamma=0.01, kernel= 'rbf').fit(X_train, y_train)\n",
    "    #clf_SVM = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "    score_test=clf_SVM.score(X_test, y_test)\n",
    "    score_train=clf_SVM.score(X_train, y_train)\n",
    "    score_cv= cross_val_score(clf_SVM, X_train, y_train, cv=10, scoring='f1_macro').mean()\n",
    "    scoretest.append(score_test)\n",
    "    scoretrain.append(score_train)\n",
    "    scorecv.append(score_cv)\n",
    "\n",
    "#     print (\"score_train = %3.3f\" % score_train)\n",
    "#     print (\"score_CV= %3.3f\" % score_cv)\n",
    "#     print (\"score_test = %3.3f\" % score_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17d1c9f3760>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " \n",
    "plt.plot(s, scoretest, 'r',label='Test')\n",
    "plt.plot(s, scorecv,'k',label='CV')\n",
    "plt.plot(s, scoretrain,'b',label='Train')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2827586206896552"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[np.argmax(scoretest)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145, 1)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[CV] batch_size=16, epochs=500 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x00000142687CF670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ........... batch_size=16, epochs=500, score=0.873, total=   2.4s\n",
      "[CV] batch_size=16, epochs=500 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function Model.make_test_function.<locals>.test_function at 0x000001427018E670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[CV] ........... batch_size=16, epochs=500, score=0.887, total=   2.4s\n",
      "[CV] batch_size=16, epochs=500 .......................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    4.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... batch_size=16, epochs=500, score=0.806, total=   2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    7.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    7.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.855521 using {'batch_size': 16, 'epochs': 500}\n",
      "0.855521 (0.035171) with: {'batch_size': 16, 'epochs': 500}\n"
     ]
    }
   ],
   "source": [
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "y_train = np.asarray(y_train).astype('float32').reshape((-1,1))\n",
    "y_test = np.asarray(y_test).astype('float32').reshape((-1,1))\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, activation='relu'))\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "# define the grid search parameters\n",
    "\n",
    "batch_size = [4, 8 , 16, 32]\n",
    "epochs = [100, 200, 500, 600, 700]\n",
    "batch_size = [16]\n",
    "epochs = [500]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=3, verbose=10)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9047619104385376"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 8, 'epochs': 200}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_result.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Rock vs Mine Prediction.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
